---
layout: post
title:  "LG Aimers 5기 멘토링데이"
subtitle:   ""
categories: [lecture] 
tag: [LG, Aimers, AI, LLM]
comments: true
---

지난 여름에 참여한 [LG Aimers](https://www.lgaimers.ai/) 5기(24.07.01~24.09.29)를 대상으로 멘토링데이 프로그램에 참여할 기회가 생겨서 마곡에 있는 LG 사이언스파크에 다녀왔다.

사전에 주제에 대한 안내가 없어서 이전 기수 후기를 몇개 보고 갔는데, 이 날은 LG AI연구원에서 개발한 생성형 AI '[EXAONE(Expert AI)](https://www.lgresearch.ai/exaone#1)'과 관련한 모델 연구와 ChatEXAONE 서비스에 대한 강의를 들을 수 있었다.

## LG AI연구원 소개
> EXAONE Lab 리더 이진식 연구원님

### [ 주요 연구 분야 ]
- Fundamental Research
- Data Intelligence
- Materials Intelligence
- Computer Vision
- Natural Language Processing, Large Language Model
- Multimodal

### [ 주요 AI 기술 상용화 사례 ]
- 고객상담 통화음성을 실시간으로 분석하여 고객상담 업무효율 개선
    - 상담 내용에 대해 실시간으로 커뮤니케이션해서 레퍼런스가 되는 문서를 띄워서 원활한 상담이 되도록
    - 상담 내용 요약 & 메모 &rarr; 이후 상담 시 참고
- EXAONE 생성이미지 기반 디자인 도안활용 타투프린터 IMPRINTU(임프린투) 출시
    - 대량의 타투 도안을 효과적으로 생성
- 비전검사 AI 기술을 활용한 스마트 팩토리 시스템 구축
    - 공장의 불량 부품 사전 예측, 검사 무인화
- LG-QRAFT AI EFT 상품 개발, 미국 뉴욕증권거래소에 상장
    - 어떻게 포트폴리오를 짜면 수익을 극대화할 수 있을지

### [ EXAONE 소개 ]
- LG의 초거대 멀티모달 AI
- 언어 및 시각 정보 이해를 바탕으로 창의적인 생성 기능을 갖추었으며, '모두를 위한 전문가 AI'를 지향함
- 효율성 / 전문성 / 신뢰성 측면에서 이점 존재

- 플랫폼 종류
    - EXAONE Universe: 전문가용 대화형 AI 플랫폼
    - EXAONE Discovery: 신소재/신물질/신약 개발 플랫폼
    - EXAONE Atelier: 창의적인 발상을 돕는 멀티모달 AI 플랫폼


### [ LG AI 윤리원칙 ]
- 무작정 데이터를 수집하지 않고, 윤리원칙에 기반하여 편향되지 않은 공정한 AI 만들기 위한 노력

---

## EXAONE 3.0 Language Model
> EXAONE Lab 이해주 연구원님

alignment squad.

![alt text](images/image-1.png)
![alt text](images/image-3.png)

### [ Benchmarks ]
- 한국어 관련 벤치마크가 없음
- MT-Bench(영어 chat) -> KoMT-Bench(한국어 chat) 개발

- Coding
- Reasoning
- General...다양한 측면에서 중간 이상의 성능

이 파트에서는 EXAONE 성능 평가를 위주로 설명해 주셨는데, LLM 분야를 잘 모르는 상태에서 들으니까 약간 어렵게 느껴졌다.
예전에 학부 프로젝트를 진행하면서 뉴스 기사 요약 모델을 평가하는 게 어려웠는데 요즘은 그때보다 LLM 평가 방법이 더 다양해지고 고도화된 것 같았다.
주로 사용하는 벤치마크 데이터셋이 무엇인지, 성능 평가 방법은 어떤 게 있는지를 얕게나마 알게 되었다.

--- 

## ChatEXAONE: Enterprise AI Agent
> Language Lab LLM-Agent Squad 리더 송호성 연구원님

[ChatEXAONE](https://www.lgresearch.ai/blog/view?seq=457)

품질/기획/마케팅/R&D..부서 다양함
생산성 측면에서 도움을 주는 서비스

### [ How it works ]
![alt text](images/image-4.png)

user history는 어떻게 DB 구성할지.. 


여기서 새로 알게 된 점
: 수학 문제 풀 때, 사람이 풀면 간단하지만 LLM은 할루시네이션이 생길수도 있고,,다양한 문제로 인해 코딩으로 푸는 방식 사용하고 있음

Q) 문제가 되는 발언 어떻게 처리하는지?   
A) red teaming..? 전문적으로 문제되는 부분 체크하는 사람 + 윤리위원회 운영 + 외부 전문업체 활용

Q) 하나의 EXAONE에 대해 아래의 여러 카테고리가 존재하는지 / 각 EXAONE을 다르게 학습했는지   
A) 둘다 아님. 자세히 말할 수 없지만 기본적으로 multi-task instruct tune? 되어있음.

Q) 챗봇 서비스에서 답변 생성 시간 오래 걸리는 문제 어떻게 해결하는지   
A) 모든 chain flow 상에 bottle nack 걸리는 부분 파악함   
    &rarr; 각 step별로 쪼개서 환경을 잘못 구축했는지, .. 어떤 이유인지 파악하는 게 제일 기본적   
    &rarr; 익숙해지면 결과물을 보면 어느쪽에 문제가 있는지 알게 됨. 그럼 그 부분 위주로 살펴봄

Q) 여행 일정 짜는 챗봇 추론 속도 문제(항공권, 숙박, 교통 등 여러개를 서치해야 하는 경우, 시간이 오래 걸림) 해결 방법?   
A) 병렬. 비동기 처리가 당연함

강의를 들으면서 약간 흥미로웠던 부분 위주로 정리한 것..ㅎㅎ 중간에 생략된 내용이 많지만 나중에 혹시라도 LG에 지원하게 된다면 참고해야겠다.
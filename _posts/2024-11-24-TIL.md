---
layout: post
title:  "[LG Aimers] 머신러닝 2. 분류 실습(Python)"
subtitle:   ""
categories: [TIL, lecture]
tag: [TIL, AI, LGAimers]
comments: true
---

LG Aimers 5기 AI 실습 교육 수강 내용을 정리합니다. 모든 자료는 교육 플랫폼 [앨리스](https://elice.io/ko)로부터 제공받았습니다.

머신러닝 2번째 파트 분류(Classification) 모델을 파이썬으로 구현해 보았습니다.

- Step01. 분류 모델 정의
- Step02. 분류 모델을 학습용 데이터에 맞추어 학습시킴(fit)
- Step03. 학습된 모델을 이용하여 테스트 데이터에 대한 예측 수행(predict)


### [ 1. 로지스틱 회귀 ]

<div markdown="1">

```python
from sklearn.linear_model import LogisticRegression

def main():
    
    train_X, test_X, train_y, test_y = load_data()
    
    logistic_model = LogisticRegression()
    logistic_model.fit(train_X, train_y)
    predicted = logistic_model.predict(test_X)
    print("예측 결과 :", predicted[:10])
    
    plot_logistic_regression(logistic_model, train_X, train_y)
    
    return logistic_model
```
<\div>


### [ 2. SVM ]

<div markdown="1">

```python
from sklearn.svm import SVC
from sklearn.metrics import classification_report, confusion_matrix 

def SVM(train_X, test_X, train_y, test_y):
    
    svm = SVC()
    
    svm.fit(train_X, train_y)
    
    pred_y = svm.predict(test_X)
    
    return pred_y
    
def main():
    
    train_X, test_X, train_y, test_y = load_data()
    
    pred_y = SVM(train_X, test_X, train_y, test_y)
    
    # SVM 분류 결과값 출력
    print("\nConfusion matrix : \n",confusion_matrix(test_y,pred_y))  
    print("\nReport : \n",classification_report(test_y,pred_y)) 

if __name__ == "__main__":
    main()

```
<\div>


### [ 3. 베이즈 정리 - Naive bayse ]
![alt text](images/image-22.png){: width="50%"}

<div markdown="1">

```python

## "확인" 이라는 키워드가 등장했을 때 해당 메일이 스팸 메일인지 정상 메일인지 판별하기 위한 함수를 구현

def bayes_theorem():
    ## 1. P(“스팸 메일”) 의 확률: 스팸메일수/전체메일수
    p_spam = 8/20
    
    ## 2. P(“확인” | “스팸 메일”) 의 확률: 스팸메일 중 확인 키워드가 포함된 메일 수/스팸메일수
    p_confirm_spam = 5/8
    
    ## 3. P(“정상 메일”) 의 확률: 정상메일수/전체메일수
    p_ham = 12/20
    
    ## 4. P(“확인” | "정상 메일" ) 의 확률: 정상메일 중 확인 키워드가 포함된 메일 수/정상메일수
    p_confirm_ham = 2/12
    
    ## 5. P( "스팸 메일" | "확인" ) 의 확률:
    ## P(스팸 메일|확인) = P(확인|스팸 메일) * P(스팸 메일) / P(확인)
    p_spam_confirm = p_confirm_spam * p_spam / (7 / 20)
    
    ## 6. P( "정상 메일" | "확인" ) 의 확률:
    ## P(정상 메일|확인) = P(확인|정상 메일) * P(정상 메일) / P(확인)
    p_ham_confirm = p_confirm_ham * p_ham / (7 / 20)
    
    return p_spam_confirm, p_ham_confirm

def main():
    
    p_spam_confirm, p_ham_confirm = bayes_theorem()
    
    print("P(spam|confirm) = ",p_spam_confirm, "\nP(ham|confirm) = ",p_ham_confirm, "\n")
        
    ## 두 값을 비교하여 확인 키워드가 스팸에 가까운지 정상 메일에 가까운지 확인합니다.
    value = [p_spam_confirm, p_ham_confirm]
    
    if p_spam_confirm > p_ham_confirm:
        print( round(value[0] * 100, 2), "% 의 확률로 스팸 메일에 가깝습니다.")
    else :
        print( round(value[1] * 100, 2), "% 의 확률로 일반 메일에 가깝습니다.")

'''
P(spam|confirm) =  0.7142857142857143 
P(ham|confirm) =  0.2857142857142857 
=> '확인' 키워드가 있을 때 스팸 메일일 확률이 0.71
'''
```
</div>

### [ 4. 베이즈 정리 - Naive bayse(Scikit-learn) ]
> 가우시안 나이브 베이즈 모델은 ‘확인’키워드 유무(O or X)와 같은 이산적 데이터가 아닌 연속적인 값(예를 들어 3.14…)을 가진 데이터에 적용할 수 있다는 특징을 가지고 있음

<div markdown="1">

```python
from sklearn.naive_bayes import GaussianNB
from sklearn.metrics import accuracy_score

def Gaussian_NB(train_X, test_X, train_y, test_y):
    
    model = GaussianNB()
    
    model.fit(train_X, train_y)
    
    predicted = model.predict(test_X)
    
    return predicted
    
def main():
    
    train_X, test_X, train_y, test_y = load_data()
    
    predicted = Gaussian_NB(train_X, test_X, train_y, test_y)
    
    print("\nModel Accuracy : ")
    print(accuracy_score(test_y, predicted))

```
</div>


### [ 5. 혼동 행렬(Confusion matrix) ]
- True Positive: 실제 Positive인 값을 Positive라고 예측(정답)
- TrueNegative: 실제 Negative인 값 Negative라고 예측(정답)
- False Positive: 실제 Negative인 값을 Positive라고 예측(오답)
- False Negative: 실제 Positive인 값을 Negative라고 예측(오답)

<div markdown="1">

```python
import numpy as np
import matplotlib.pyplot as plt

from sklearn.svm import SVC
from sklearn.metrics import confusion_matrix
from sklearn.utils.multiclass import unique_labels

# Confusion matrix 시각화를 위한 함수입니다.
def plot_confusion_matrix(cm, y_true, y_pred, classes, normalize=False, cmap=plt.cm.OrRd):
                          
    title = ""
    if normalize:
        title = 'Normalized confusion matrix'
    else:
        title = 'Confusion matrix'
    
    classes = classes[unique_labels(y_true, y_pred)]
    if normalize:
        # 정규화 할 때는 모든 값을 더해서 합이 1이 되도록 각 데이터를 스케일링 합니다.
        cm = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]

    print(title, ":\n", cm)

    fig, ax = plt.subplots()
    im = ax.imshow(cm, interpolation='nearest', cmap=cmap)
    ax.figure.colorbar(im, ax=ax)
    ax.set(xticks=np.arange(cm.shape[1]),
           yticks=np.arange(cm.shape[0]),
           xticklabels=classes, yticklabels=classes,
           title=title,
           ylabel='True label',
           xlabel='Predicted label')

    # label을 45도 회전해서 보여주도록 변경
    plt.setp(ax.get_xticklabels(), rotation=45, ha="right",
             rotation_mode="anchor")

    # confusion matrix 실제 값 뿌리기
    fmt = '.2f' if normalize else 'd'
    thresh = cm.max() / 2.
    for i in range(cm.shape[0]):
        for j in range(cm.shape[1]):
            ax.text(j, i, format(cm[i, j], fmt),
                    ha="center", va="center",
                    color="white" if cm[i, j] > thresh else "black")
    fig.tight_layout()
    
    plt.savefig('confusion matrix.png')
    elice_utils.send_image('confusion matrix.png')

def main():
    
    train_X, test_X, train_y, test_y, class_names = load_data()
    
    ## SVM 모델 생성, 학습
    classifier = SVC()
    y_pred = classifier.fit(train_X, train_y).predict(test_X)
    
    cm = confusion_matrix(test_y, y_pred)
    
    plot_confusion_matrix(cm, test_y, y_pred, classes=class_names)
    
    ## 정규화 된 혼동 행렬 시각화
    plot_confusion_matrix(cm, test_y, y_pred, classes=class_names, normalize = True)
    
    return cm
```
</div>

### [ 6. 정확도, 정밀도, 재현율 ]
![alt text](images/image-20.png){: width="50%"}

- 정확도(accuracy): (TP+TN) / (TP+FP+FN+TN)
- 정밀도(precision): TP / (TP+FP)
- 재현율(recall): TP / (TP+FN)
> 데이터가 불균형하거나 다양한 상황에서 정확도만으로는 모델을 평가하는 데 한계가 있으므로 다른 지표들을 함께 사용함

![alt text](images/image-21.png){: width="50%"}

<div markdown="1">

```python
import pandas as pd

def main():
    # 실제 값
    y_true = pd.Series(
        ["not mafia", "not mafia", "mafia", "not mafia", "mafia", 
        "not mafia", "not mafia", "mafia", "not mafia", "not mafia"]
        )
    # 예측된 값
    y_pred = pd.Series(
        ["mafia", "mafia", "not mafia", "not mafia", "mafia", 
        "not mafia", "not mafia", "mafia", "not mafia", "not mafia"]
        )
    
    print("1. 혼동 행렬 :\n",pd.crosstab(y_true, y_pred, rownames=['실제'], colnames=['예측'], margins=True))
    
    """
    1. 실행 버튼을 클릭하여 마피아(mafia)와 시민(not mafia)으로 분류된 혼동 행렬을 확인함
    """
    
    """
    2. 실행 결과값을 토대로 마피아를 제대로 분석했는 지에 대한 accuracy, precision, recall을 구함
    """
    accuracy = (2+5)/10
    
    precision = 2/4
    
    recall = 2/3
    
    print("\naccuracy : ", accuracy)
    print("precision : ", precision)
    print("recall : ", recall)
    
    return accuracy, precision, recall
```
</div>

<!DOCTYPE html><html lang="ko-KR" ><head><meta http-equiv="Content-Type" content="text/html; charset=UTF-8"><meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no"><meta name="day-prompt" content="days ago"><meta name="hour-prompt" content="hours ago"><meta name="minute-prompt" content="minutes ago"><meta name="justnow-prompt" content="just now"><meta name="generator" content="Jekyll v4.4.1" /><meta property="og:title" content="[논문리뷰] A Review of Generalized Zero-Shot Learning Methods(2022)" /><meta property="og:locale" content="ko_KR" /><meta name="description" content="Pourpanah, F., Abdar, M., Luo, Y., Zhou, X., Wang, R., Lim, C. P., … &amp; Wu, Q. J. (2022). A review of generalized zero-shot learning methods. IEEE transactions on pattern analysis and machine intelligence." /><meta property="og:description" content="Pourpanah, F., Abdar, M., Luo, Y., Zhou, X., Wang, R., Lim, C. P., … &amp; Wu, Q. J. (2022). A review of generalized zero-shot learning methods. IEEE transactions on pattern analysis and machine intelligence." /><link rel="canonical" href="https://jiyeonnn03.github.io/posts/paper_ai_1/" /><meta property="og:url" content="https://jiyeonnn03.github.io/posts/paper_ai_1/" /><meta property="og:site_name" content="Developer Yeon" /><meta property="og:type" content="article" /><meta property="article:published_time" content="2023-04-03T00:00:00+09:00" /><meta name="twitter:card" content="summary" /><meta property="twitter:title" content="[논문리뷰] A Review of Generalized Zero-Shot Learning Methods(2022)" /> <script type="application/ld+json"> {"@context":"https://schema.org","@type":"BlogPosting","dateModified":"2023-04-14T17:13:48+09:00","datePublished":"2023-04-03T00:00:00+09:00","description":"Pourpanah, F., Abdar, M., Luo, Y., Zhou, X., Wang, R., Lim, C. P., … &amp; Wu, Q. J. (2022). A review of generalized zero-shot learning methods. IEEE transactions on pattern analysis and machine intelligence.","headline":"[논문리뷰] A Review of Generalized Zero-Shot Learning Methods(2022)","mainEntityOfPage":{"@type":"WebPage","@id":"https://jiyeonnn03.github.io/posts/paper_ai_1/"},"url":"https://jiyeonnn03.github.io/posts/paper_ai_1/"}</script><title>[논문리뷰] A Review of Generalized Zero-Shot Learning Methods(2022) | Developer Yeon</title><link rel="apple-touch-icon" sizes="180x180" href="/assets/img/favicons/apple-touch-icon.png"><link rel="icon" type="image/png" sizes="32x32" href="/assets/img/favicons/favicon-32x32.png"><link rel="icon" type="image/png" sizes="16x16" href="/assets/img/favicons/favicon-16x16.png"><link rel="manifest" href="/assets/img/favicons/site.webmanifest"><link rel="shortcut icon" href="/assets/img/favicons/favicon.ico"><meta name="apple-mobile-web-app-title" content="Developer Yeon"><meta name="application-name" content="Developer Yeon"><meta name="msapplication-TileColor" content="#da532c"><meta name="msapplication-config" content="/assets/img/favicons/browserconfig.xml"><meta name="theme-color" content="#ffffff"><link rel="preconnect" href="https://fonts.gstatic.com" crossorigin="anonymous"><link rel="dns-prefetch" href="https://fonts.gstatic.com"><link rel="preconnect" href="https://www.google-analytics.com" crossorigin="use-credentials"><link rel="dns-prefetch" href="https://www.google-analytics.com"><link rel="preconnect" href="https://www.googletagmanager.com" crossorigin="anonymous"><link rel="dns-prefetch" href="https://www.googletagmanager.com"><link rel="preconnect" href="https://cdn.jsdelivr.net"><link rel="dns-prefetch" href="https://cdn.jsdelivr.net"><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/bootstrap@4.0.0/dist/css/bootstrap.min.css"><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/@fortawesome/fontawesome-free@5.11.2/css/all.min.css"><link rel="stylesheet" href="/assets/css/style.css"><link rel="stylesheet" href="https://cdn.jsdelivr.net/gh/afeld/bootstrap-toc@1.0.1/dist/bootstrap-toc.min.css"><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/magnific-popup@1.1.0/dist/magnific-popup.min.css"> <script src="https://cdn.jsdelivr.net/npm/jquery@3/dist/jquery.min.js"></script><body data-spy="scroll" data-target="#toc"><div id="sidebar" class="d-flex flex-column align-items-end" lang="en"><div class="profile-wrapper text-center"><div id="avatar"> <a href="/" alt="avatar" class="mx-auto"> <img src="/assets/img/profile.jpg" alt="avatar" onerror="this.style.display='none'"> </a></div><div class="site-title mt-3"> <a href="/">Developer Yeon</a></div><div class="site-subtitle font-italic">Undergraduate Student in KW Univ.</div></div><ul class="w-100"><li class="nav-item"> <a href="/" class="nav-link"> <i class="fa-fw fas fa-home ml-xl-3 mr-xl-3 unloaded"></i> <span>HOME</span> </a><li class="nav-item"> <a href="/categories/" class="nav-link"> <i class="fa-fw fas fa-stream ml-xl-3 mr-xl-3 unloaded"></i> <span>CATEGORIES</span> </a><li class="nav-item"> <a href="/tags/" class="nav-link"> <i class="fa-fw fas fa-tag ml-xl-3 mr-xl-3 unloaded"></i> <span>TAGS</span> </a><li class="nav-item"> <a href="/archives/" class="nav-link"> <i class="fa-fw fas fa-archive ml-xl-3 mr-xl-3 unloaded"></i> <span>ARCHIVES</span> </a><li class="nav-item"> <a href="/about/" class="nav-link"> <i class="fa-fw fas fa-info-circle ml-xl-3 mr-xl-3 unloaded"></i> <span>ABOUT</span> </a></ul><div class="sidebar-bottom mt-auto d-flex flex-wrap justify-content-center align-items-center"> <a href="https://github.com/jiyeonnn03" aria-label="github" class="order-3" target="_blank" rel="noopener"> <i class="fab fa-github"></i> </a> <a href=" javascript:location.href = 'mailto:' + ['',''].join('@')" aria-label="email" class="order-4" > <i class="fas fa-envelope"></i> </a> <a href="/feed.xml" aria-label="rss" class="order-5" > <i class="fas fa-rss"></i> </a> <span class="icon-border order-2"></span> <span id="mode-toggle-wrapper" class="order-1"> <i class="mode-toggle fas fa-adjust"></i> <script type="text/javascript"> class ModeToggle { static get MODE_KEY() { return "mode"; } static get DARK_MODE() { return "dark"; } static get LIGHT_MODE() { return "light"; } constructor() { if (this.hasMode) { if (this.isDarkMode) { if (!this.isSysDarkPrefer) { this.setDark(); } } else { if (this.isSysDarkPrefer) { this.setLight(); } } } var self = this; /* always follow the system prefers */ this.sysDarkPrefers.addListener(function() { if (self.hasMode) { if (self.isDarkMode) { if (!self.isSysDarkPrefer) { self.setDark(); } } else { if (self.isSysDarkPrefer) { self.setLight(); } } self.clearMode(); } self.updateMermaid(); }); } /* constructor() */ setDark() { $('html').attr(ModeToggle.MODE_KEY, ModeToggle.DARK_MODE); sessionStorage.setItem(ModeToggle.MODE_KEY, ModeToggle.DARK_MODE); } setLight() { $('html').attr(ModeToggle.MODE_KEY, ModeToggle.LIGHT_MODE); sessionStorage.setItem(ModeToggle.MODE_KEY, ModeToggle.LIGHT_MODE); } clearMode() { $('html').removeAttr(ModeToggle.MODE_KEY); sessionStorage.removeItem(ModeToggle.MODE_KEY); } get sysDarkPrefers() { return window.matchMedia("(prefers-color-scheme: dark)"); } get isSysDarkPrefer() { return this.sysDarkPrefers.matches; } get isDarkMode() { return this.mode == ModeToggle.DARK_MODE; } get isLightMode() { return this.mode == ModeToggle.LIGHT_MODE; } get hasMode() { return this.mode != null; } get mode() { return sessionStorage.getItem(ModeToggle.MODE_KEY); } /* get the current mode on screen */ get modeStatus() { if (this.isDarkMode || (!this.hasMode && this.isSysDarkPrefer) ) { return ModeToggle.DARK_MODE; } else { return ModeToggle.LIGHT_MODE; } } updateMermaid() { if (typeof mermaid !== "undefined") { let expectedTheme = (this.modeStatus === ModeToggle.DARK_MODE? "dark" : "default"); let config = { theme: expectedTheme }; /* re-render the SVG › <https://github.com/mermaid-js/mermaid/issues/311#issuecomment-332557344> */ $(".mermaid").each(function() { let svgCode = $(this).prev().children().html(); $(this).removeAttr("data-processed"); $(this).html(svgCode); }); mermaid.initialize(config); mermaid.init(undefined, ".mermaid"); } } flipMode() { if (this.hasMode) { if (this.isSysDarkPrefer) { if (this.isLightMode) { this.clearMode(); } else { this.setLight(); } } else { if (this.isDarkMode) { this.clearMode(); } else { this.setDark(); } } } else { if (this.isSysDarkPrefer) { this.setLight(); } else { this.setDark(); } } this.updateMermaid(); } /* flipMode() */ } /* ModeToggle */ let toggle = new ModeToggle(); $(".mode-toggle").click(function() { toggle.flipMode(); }); </script> </span></div></div><div id="topbar-wrapper" class="row justify-content-center topbar-down"><div id="topbar" class="col-11 d-flex h-100 align-items-center justify-content-between"> <span id="breadcrumb"> <span> <a href="/"> Home </a> </span> <span>[논문리뷰] A Review of Generalized Zero-Shot Learning Methods(2022)</span> </span> <i id="sidebar-trigger" class="fas fa-bars fa-fw"></i><div id="topbar-title"> Post</div><i id="search-trigger" class="fas fa-search fa-fw"></i> <span id="search-wrapper" class="align-items-center"> <i class="fas fa-search fa-fw"></i> <input class="form-control" id="search-input" type="search" aria-label="search" autocomplete="off" placeholder="Search..."> <i class="fa fa-times-circle fa-fw" id="search-cleaner"></i> </span> <span id="search-cancel" >Cancel</span></div></div><div id="main-wrapper"><div id="main"><div class="row"><div id="post-wrapper" class="col-12 col-lg-11 col-xl-8"><div class="post pl-1 pr-1 pl-sm-2 pr-sm-2 pl-md-4 pr-md-4"><h1 data-toc-skip>[논문리뷰] A Review of Generalized Zero-Shot Learning Methods(2022)</h1><div class="post-meta text-muted d-flex flex-column"><div> <span class="semi-bold"> </span> on <span class="timeago " data-toggle="tooltip" data-placement="bottom" title="Mon, Apr 3, 2023, 12:00 AM +0900" >Apr 3, 2023<i class="unloaded">2023-04-03T00:00:00+09:00</i> </span></div><div> <span> Updated <span class="timeago lastmod" data-toggle="tooltip" data-placement="bottom" title="Fri, Apr 14, 2023, 5:13 PM +0900" >Apr 14, 2023<i class="unloaded">2023-04-14T17:13:48+09:00</i> </span> </span> <span class="readtime" data-toggle="tooltip" data-placement="bottom" title="1550 words">8 min read</span></div></div><div class="post-content"><blockquote><p>Pourpanah, F., Abdar, M., Luo, Y., Zhou, X., Wang, R., Lim, C. P., … &amp; Wu, Q. J. (2022). A review of generalized zero-shot learning methods. IEEE transactions on pattern analysis and machine intelligence.</p></blockquote><blockquote><p><a href="https://arxiv.org/abs/2011.08641">논문 다운로드(arxiv)</a></p></blockquote><p>#</p><h1 id="-1-introduction-"><strong>[ 1. Introduction ]</strong></h1><ul><li>기존 이미지 처리, 컴퓨터 비전 분야에서 딥러닝 모델의 발전<ul><li>feature extraction에서 classification까지 end-to-end solution을 제공하는 기능으로 인기를 얻음<li>학습을 위해 여전히 많은 양의 sample과 class에 대한 label data를 필요로 함<li>이러한 대용량의 labeled data를 수집하는 것은 어렵고 training data에 있는 class가 아닌 경우(unseen data) 분류가 불가능하다는 문제가 존재함<li>모든 class에 대한 labeling 어려움(추가적인 도메인 지식 필요)</ul><li>다양한 학습 구성을 위한 기술<ul><li>One-shot learning<li>Few-shot learning<li>OSR(Open Set Recognition) : unseen class에 속하지만 정확한 class label 예측 불가<li><p>Out-of-distribution : training sample과 다른 test sample을 식별하고자 하지만 불가</p><li>인간은 대체로 약 3만개의 카테고리를 인식할 수 있으며, 모든 카테고리를 배우지 않고도 파악이 가능함<li>예) ‘말(horse)’을 본 적이 있는 아이는 얼룩말을 보고 ‘흑백 줄무늬가 있는 말’이라고 생각할 수 있음</ul><p>→ 다른 class data sample에서 얻은 knoledge를 사용하고 sample이 거의 없는 class 처리를 위한 classification model을 공식화 함</p><li>ZSL의 목표<ul><li>seen class(source domain)로부터 얻은 transferring knowledge를 통해 unseen class(target domain)의 객체를 분류하는 학습 모델 구축<li>semantic information을 사용하여 seen/unseen class 간 격차 해소<ul><li>seen, unseen class의 name을 고차원 벡터에 포함하며 아래의 벡터이거나 벡터들의 조합으로 구성<li>수동으로 정의된 attribute vector<li>자동으로 추출된 word vector<li>context 기반의 embedding</ul><li>test data는 unseen class 로만 구성되지만, 실제로는 unseen class만 분류하는 것보다 seen/unseen class를 동시에 인식해야 함</ul><p>⇒ <strong>“GZSL; Generalized Zero Shot Learning”</strong></p><p><img data-proofer-ignore data-src="https://user-images.githubusercontent.com/49242144/230734286-94a34ee8-6e10-4b6f-93c3-4a41074dd7a9.png" alt="Fig1" /></p></ul><h3 id="1-contributions"><strong>1. Contributions</strong></h3><ul><li>ZSL 관련 연구 논문 [3], [24], [26], [27] 와의 차이점<li>[3]은 ZSL, few GZSL method에 초점을 맞춤<li>[24] ZSL, GZSL method에 대해 각각 서로 다른 case study(different data set 사용) 진행했으며, ZSL, GZSL method 자체보다 empirical research에 중점을 둠<li>[26] GZSL에 대한 간단한 논의 + ZSL에 초점을 맞춤<li><p>[27] COVID-19 질병을 위한 ZSL method의 중요성 강조</p><p>→ ZSL보다 GZSL에 대한 in-depth survey and analysis를 포함한 기존 논문이 존재하지 않음</p><p>⇒ 본 논문은 GZSL에 대한 포괄적인 review 제공(problem formulation, challenging issue, hierarchical categorization, applications..)을 목표로 함</p><li>The main contributions of this review paper include:<ul><li>comprehensive review of the GZSL methods, to the best of our knowledge, this is the first paper that attempts to provide an in-depth analysis of the GZSL methods;<li>hierarchical categorization of the GZSL methods along with their corresponding representative models and real-world applications;<li>elucidation on the main research gaps and suggestions for future research directions.</ul></ul><h3 id="2-organization"><strong>2. Organization</strong></h3><ul><li><p>섹션별 주요 내용</p><ol><li>Overview of GZSL<ul><li>problem formulation<li>semantic information<li>embedding spaces<li>challenging issues</ul><li>Inductive and semantic transductive GZSL methods<li>The transductive GZSL methods<li>The applications of GZSL to various domains<li>Discussion on the research gaps and trends for future research</ol></ul><h1 id="-2-overview-of-generalized-zero-shot-learning-"><strong>[ 2. Overview of Generalized Zero-Shot Learning ]</strong></h1><h3 id="1-problem-formulation"><strong>1. Problem Formulation</strong></h3><ul><li>GZSL 학습 단계 <img data-proofer-ignore data-src="https://user-images.githubusercontent.com/49242144/230734584-b46a3b87-774d-4c1b-8b43-6dd97328e17d.png" alt="Fig2" /><ul><li>Inductive learning<ul><li>seen class의 visual feature + semantic information 만으로 모델 구축</ul><li>Transductive learning<ul><li>unseen class의 unlabeled visual feature + semantic information 활용</ul></ul></ul><h3 id="2-performance-indicators"><strong>2. Performance Indicators</strong></h3><ul><li>Accuracy of seen (Acc s)<li>Accuracy of unseen (Acc u)<li>Area Under Seen-Unseen Accuracy Curve (AUSUC)<ul><li>AUSUC value 높을수록 GZSL task에서 balanced performance를 달성하는 것을 목표로 함</ul><li><p>Harmonic Mean (HM) <img data-proofer-ignore data-src="https://user-images.githubusercontent.com/49242144/230734804-d6495a30-3cc7-41fa-8b35-b157e66648ae.png" alt="math" /></p><ul><li>GZSL이 seen class 에 편향된 경우 ⇒ Acc s &gt; Acc u ⇒ HM score 낮아짐</ul></ul><h3 id="3-semantic-information"><strong>3. Semantic Information</strong></h3><ul><li>unseen class는 label이 없으므로 semantic information을 사용하여 seen class와 unseen class 간 관계를 구축 → ZSL에 활용<li>semantic information 은 모든 unseen class의 recognition properties를 포함해야하며, 사용성 보장을 위해 feature space의 sample과 관련이 있어야 함<li>종류<ul><li>Manually defined attributes<li>Word vectors<li>?.?</ul></ul><h3 id="4-embedding-spaces"><strong>4. Embedding spaces</strong></h3><p><img data-proofer-ignore data-src="https://user-images.githubusercontent.com/49242144/230734333-fba25123-4038-4795-b1af-c59b2f8a4f51.png" alt="Fig3" /></p><ul><li>Semantic Embedding<ul><li>class에 속하는 모든 이미지의 semantic embedding을 일부 ground-truth label embedding에 맵핑하도록 하는 것<li>nearest neighbor search를 사용하여 test image 인식 가능</ul><li>Visual Embedding<ul><li>semantic representation을 해당 visual feature와 가깝게 만드는 것<li>nearest neighbor search를 사용하여 test image 인식 가능</ul><li>Latent Embedding<ul><li>semantic/visual embedding space 사이의 explicit projection function을 학습하는 것은 어려움 → semantic/visual representation을 common space에 투영<li>intra-class compactness, inter-class separability를 만족해야 함</ul></ul><h3 id="5-challenging-issues"><strong>5. Challenging Issues</strong></h3><p><img data-proofer-ignore data-src="https://user-images.githubusercontent.com/49242144/230735431-4b6d6c9d-1d52-44bd-bc8e-6ec79d723b7c.png" alt="Fig4-5" /></p><ul><li>Fig 4.<ul><li>(a) Ideal mapping result<li>(b) Practical mapping result</ul><li>Fig 5.<ul><li>GZSL은 seen/unseen class 모두에 대한 인식을 수행하는 모델을 학습하므로, 일반적으로 seen class에 편향되고 unseen class data가 seen class로 잘못 분류됨<li>대부분의 ZSL은 이 문제를 효과적으로 해결할 수 없으므로, calibrated stacking, novelty detector..제안<ul><li>calibrated stacking : seen/unseen class 모두에서 균형있게 인식하도록 함<ul><li>scaled calibration &amp; probabilistic representation 도 유사한 방법</ul><li>detector : test sample이 seen/unseen 중 어느 class에 속하는지 식별하도록 함</ul></ul></ul><h1 id="-3-review-of-gzsl-methods-">[ 3. Review of GZSL Methods ]</h1><h3 id="1-embedding-based-methods"><strong>1. Embedding-based methods</strong></h3><p><img data-proofer-ignore data-src="https://user-images.githubusercontent.com/49242144/230734810-24dbf62c-9948-421a-a6aa-26f6e2b767fa.png" alt="Fig6a" /></p><ul><li><p>embedding space 학습 → seen class의 low-level visual feature을 해당 semantic vector와 연결</p><li><p>GZSL 문제를 해결하기 위한 다양한 embedding based method <img data-proofer-ignore data-src="https://user-images.githubusercontent.com/49242144/230735122-33933535-b801-4f47-96b4-4101b10b32a7.png" alt="Fig7" /></p></ul><ol><li><p>Out-of-distribution Detection-based Methods</p><li><p>Graph-based Methods <img data-proofer-ignore data-src="https://user-images.githubusercontent.com/49242144/230735022-4c0a2762-e8ff-4604-8d66-0da6e8b82a5f.png" alt="Fig8" /></p><li><p>Meta Learning-based Methods</p><li><p>Attention-based Methods <img data-proofer-ignore data-src="https://user-images.githubusercontent.com/49242144/230735094-ae9df419-a3e6-447b-849c-225c1e0b2f11.png" alt="Fig9" /></p><li><p>Compositional Learning-based Methods</p><li><p>Bidirectional Learning Methods</p><li><p>Autoencoder-based Methods</p><li><p>Other methods</p></ol><h3 id="2-generative-based-methods"><strong>2. Generative-based methods</strong></h3><p><img data-proofer-ignore data-src="https://user-images.githubusercontent.com/49242144/230734900-c5ddafd7-4813-48f3-9065-7cd54194eb5c.png" alt="Fig6b" /></p><ul><li>seen/unseen class의 semantic representation을 기반으로 unseen class에 대한 image/visual feature를 생성하는 모델 학습<ol><li>Generative Adversarial networks <img data-proofer-ignore data-src="https://user-images.githubusercontent.com/49242144/230735549-4faf4fb9-6b62-4d37-b3f5-a656060bbc08.png" alt="Fig10" /></ol></ul><ol><li><p>Variational Autoencoders(VAEs) <img data-proofer-ignore data-src="https://user-images.githubusercontent.com/49242144/230735546-95b1aad5-15cd-4c1b-bb2f-1f0a5fe3da7d.png" alt="Fig11" /></p><li><p>Combined GANs and VAEs</p><li><p>Other Methods</p></ol><h1 id="-4-transductive-gazsl-methods-"><strong>[ 4. Transductive GAZSL Methods ]</strong></h1><ul><li>unlabeled data에 접근 → 모델이 unseen class의 분포 파악 가능 ⇒ discriminative projection function 학습 가능</ul><h3 id="1-embedding-based-methods-1"><strong>1. Embedding-based methods</strong></h3><ul><li>Quasi-fully supervised learning(QFSL) <img data-proofer-ignore data-src="https://user-images.githubusercontent.com/49242144/230734976-bb816ed5-01f4-4413-bd75-3477eeba2c04.png" alt="Fig12" /></ul><h3 id="2-generative-based-methods-1"><strong>2. Generative-based methods</strong></h3><h1 id="-5-applications-"><strong>[ 5. Applications ]</strong></h1><ul><li>최근 CV, NLP에 적용 → image classification, object detection, video processing, NLP</ul><h3 id="1-computer-vision"><strong>1. Computer vision</strong></h3><ul><li>image processing<li>video processing</ul><p><img data-proofer-ignore data-src="https://user-images.githubusercontent.com/49242144/230735608-00b1a702-89e7-4079-94e1-d301ef50f717.png" alt="Table1" /></p><h3 id="2-natural-language-processing"><strong>2. Natural language processing</strong></h3><h1 id="-6-discussions-and-conclusions-"><strong>[ 6. Discussions and Conclusions ]</strong></h1><ul><li><p>Highlights of GZSL methods</p><p><img data-proofer-ignore data-src="https://user-images.githubusercontent.com/49242144/230735609-b9aafa28-397e-4686-8c52-30d0d8e5955b.png" alt="Table2" /></p><ul><li>Embedding<ul><li>장점<ul><li>구조가 덜 복잡하고 구현하기 쉬움<li>데이터셋 속성에 따라 linear, non-linear 등 다양한 projection function 선택 가능</ul><li>단점<ul><li>semantic embedding space 학습 시, hubness, shift, bias 문제<li>visual/latent space 학습 시, shift, bias 문제</ul></ul><li>Generative<ul><li>장점<ul><li>unseen class에 대한 많은 샘플 생성 가능<li>다양한 supervised model 사용 가능</ul><li>단점<ul><li>구조가 복잡하고 학습이 어려우며, 학습이 불안정해 mode collapse issue 존재</ul></ul></ul><li><p>Highlights of embedding and generative-based methods</p><p><img data-proofer-ignore data-src="https://user-images.githubusercontent.com/49242144/230735611-92857610-4ee8-4642-9232-051267cf5f95.png" alt="Table3" /></p></ul><h3 id="a-summary-of-zsl-methods"><strong>A summary of ZSL methods</strong></h3><p><img data-proofer-ignore data-src="https://user-images.githubusercontent.com/49242144/230735657-e49dda1e-8d0a-4460-947c-b1ac45e1baff.png" alt="Table4" /></p><p><img data-proofer-ignore data-src="https://user-images.githubusercontent.com/49242144/230735661-5d0e5ec4-994d-4e17-b604-353da0e45bea.png" alt="Table5" /></p><p><img data-proofer-ignore data-src="https://user-images.githubusercontent.com/49242144/230735668-a616097b-8822-42be-8d89-401b7eaea2ec.png" alt="Table6" /></p></div><div class="post-tail-wrapper text-muted"><div class="post-meta mb-3"> <i class="far fa-folder-open fa-fw mr-1"></i> <a href='/categories/paper-review/'>paper_review</a></div><div class="post-tags"> <i class="fa fa-tags fa-fw mr-1"></i> <a href="/tags/paper-review/" class="post-tag no-text-decoration" >paper-review</a> <a href="/tags/ai/" class="post-tag no-text-decoration" >ai</a> <a href="/tags/image-data/" class="post-tag no-text-decoration" >image-data</a> <a href="/tags/zero-shot-learning/" class="post-tag no-text-decoration" >zero-shot-learning</a></div><div class="post-tail-bottom d-flex justify-content-between align-items-center mt-3 pt-5 pb-2"><div class="license-wrapper"> This post is licensed under <a href="https://creativecommons.org/licenses/by/4.0/"> CC BY 4.0 </a> by the author.</div><div class="share-wrapper"> <span class="share-label text-muted mr-1">Share</span> <span class="share-icons"> <a href="https://twitter.com/intent/tweet?text=[논문리뷰] A Review of Generalized Zero-Shot Learning Methods(2022) - Developer Yeon&url=https://jiyeonnn03.github.io/posts/paper_ai_1/" data-toggle="tooltip" data-placement="top" title="Twitter" target="_blank" rel="noopener" aria-label="Twitter"> <i class="fa-fw fab fa-twitter"></i> </a> <a href="https://www.facebook.com/sharer/sharer.php?title=[논문리뷰] A Review of Generalized Zero-Shot Learning Methods(2022) - Developer Yeon&u=https://jiyeonnn03.github.io/posts/paper_ai_1/" data-toggle="tooltip" data-placement="top" title="Facebook" target="_blank" rel="noopener" aria-label="Facebook"> <i class="fa-fw fab fa-facebook-square"></i> </a> <a href="https://telegram.me/share?text=[논문리뷰] A Review of Generalized Zero-Shot Learning Methods(2022) - Developer Yeon&url=https://jiyeonnn03.github.io/posts/paper_ai_1/" data-toggle="tooltip" data-placement="top" title="Telegram" target="_blank" rel="noopener" aria-label="Telegram"> <i class="fa-fw fab fa-telegram"></i> </a> <i id="copy-link" class="fa-fw fas fa-link small" data-toggle="tooltip" data-placement="top" title="Copy link" title-succeed="Link copied successfully!"> </i> </span></div></div></div></div></div><div id="panel-wrapper" class="col-xl-3 pl-2 text-muted topbar-down"><div class="access"><div id="access-lastmod" class="post"> <span>Recent Update</span><ul class="post-content pl-0 pb-1 ml-1 mt-2"><li><a href="/posts/TIL-%EB%94%A5%EB%9F%AC%EB%8B%9D%EA%B8%B0%EC%B4%883/">[LG Aimers] 딥러닝 기초 3. 과적합 실습(Python)</a><li><a href="/posts/TIL/">24.11.05(Tue)</a><li><a href="/posts/TIL/">24.11.06(Wed)</a><li><a href="/posts/TIL/">24.11.07(Thu)</a><li><a href="/posts/TIL/">24.11.08(Fri)</a></ul></div><div id="access-tags"> <span>Trending Tags</span><div class="d-flex flex-wrap mt-3 mb-1 mr-3"> <a class="post-tag" href="/tags/til/">TIL</a> <a class="post-tag" href="/tags/tir/">TIR</a> <a class="post-tag" href="/tags/99%ED%81%B4%EB%9F%BD/">99클럽</a> <a class="post-tag" href="/tags/%EA%B0%9C%EB%B0%9C%EC%9E%90%EC%B7%A8%EC%97%85/">개발자취업</a> <a class="post-tag" href="/tags/%EC%BD%94%EB%94%A9%ED%85%8C%EC%8A%A4%ED%8A%B8%EC%A4%80%EB%B9%84/">코딩테스트준비</a> <a class="post-tag" href="/tags/%ED%95%AD%ED%95%B499/">항해99</a> <a class="post-tag" href="/tags/ai/">AI</a> <a class="post-tag" href="/tags/lgaimers/">LGAimers</a> <a class="post-tag" href="/tags/paper-review/">paper-review</a> <a class="post-tag" href="/tags/ai/">ai</a></div></div></div><script src="https://cdn.jsdelivr.net/gh/afeld/bootstrap-toc@1.0.1/dist/bootstrap-toc.min.js"></script><div id="toc-wrapper" class="pl-0 pr-4 mb-5"> <span class="pl-3 pt-2 mb-2">Contents</span><nav id="toc" data-toggle="toc"></nav></div></div></div><div class="row"><div class="col-12 col-lg-11 col-xl-8"><div id="post-extend-wrapper" class="pl-1 pr-1 pl-sm-2 pr-sm-2 pl-md-4 pr-md-4"><div id="related-posts" class="mt-5 mb-2 mb-sm-4"><h3 class="pt-2 mt-1 mb-4 ml-1" data-toc-skip>Further Reading</h3><div class="card-deck mb-4"><div class="card"> <a href="/posts/paper_ai_2/"><div class="card-body"> <span class="timeago small" >Apr 10, 2023<i class="unloaded">2023-04-10T00:00:00+09:00</i> </span><h3 class="pt-0 mt-1 mb-3" data-toc-skip>[논문리뷰] Temporal Fusion Transformers for Interpretable Multi-horizon Time Series Forecasting</h3><div class="text-muted small"><p> Temporal Fusion Transformers for Interpretable Multi-horizon Time Series Forecasting(2019) google-research-TFT(github) # 1. Introduction</p></div></div></a></div><div class="card"> <a href="/posts/paper_pm_1/"><div class="card-body"> <span class="timeago small" >Apr 13, 2023<i class="unloaded">2023-04-13T00:00:00+09:00</i> </span><h3 class="pt-0 mt-1 mb-3" data-toc-skip>[논문리뷰] SAP Signavio Academic Models: A Large Process Model Dataset(2022)</h3><div class="text-muted small"><p> Sola, D., Warmuth, C., Schäfer, B., Badakhshan, P., Rehse, J. R., &amp; Kampik, T. (2023, March). SAP Signavio Academic Models: A Large Process Model Dataset. In Process Mining Workshops: ICPM 2...</p></div></div></a></div><div class="card"> <a href="/posts/TIL-%ED%95%AD%ED%95%B4%EC%BD%94%ED%85%8C%EC%8A%A4%ED%84%B0%EB%94%949%EC%9D%BC%EC%B0%A8/"><div class="card-body"> <span class="timeago small" >Apr 10<i class="unloaded">2025-04-10T00:00:00+09:00</i> </span><h3 class="pt-0 mt-1 mb-3" data-toc-skip>[TIL] 99클럽 코테 스터디 6기 9일차 TIL - [그리디] 저울</h3><div class="text-muted small"><p> 오늘의 문제 2437. 저울(골드2) 키워드 그리디, 정렬 나의 풀이 1 2 3 4 5 6 7 8 9 10 11 12 13 N = int(input()) weights = list(map(int, input().split())) weights.sort() sum_weight = 0 for i in range(N) : if sum_w...</p></div></div></a></div></div></div><div class="post-navigation d-flex justify-content-between"> <a href="/posts/kobartsum/" class="btn btn-outline-primary" prompt="Older"><p>[KoBART-summarization] fine-tuning 및 모델 추출 방법</p></a> <a href="/posts/paper_ai_2/" class="btn btn-outline-primary" prompt="Newer"><p>[논문리뷰] Temporal Fusion Transformers for Interpretable Multi-horizon Time Series Forecasting</p></a></div><div id="disqus_thread" class="pt-2 pb-2"><p class="text-center text-muted small"> Comments powered by <a href="https://disqus.com/">Disqus</a>.</p></div><script type="text/javascript"> var disqus_config = function () { this.page.url = 'https://jiyeonnn03.github.io/posts/paper_ai_1/'; this.page.identifier = '/posts/paper_ai_1/'; }; /* Lazy loading */ var disqus_observer = new IntersectionObserver(function (entries) { if(entries[0].isIntersecting) { (function () { var d = document, s = d.createElement('script'); // s.src = 'https://jiyeonnn03-github-io.disqus.com/embed.js'; s.src = 'https://jiyeonnn03-github-io.disqus.com/embed.js'; s.setAttribute('data-timestamp', +new Date()); (d.head || d.body).appendChild(s); })(); disqus_observer.disconnect(); } }, { threshold: [0] }); disqus_observer.observe(document.querySelector('#disqus_thread')); /* Auto switch theme */ function reloadDisqus() { /* Disqus hasn't been loaded */ if (typeof DISQUS === "undefined") { return; } if (document.readyState == 'complete') { DISQUS.reset({ reload: true, config: disqus_config }); } } const modeToggle = document.querySelector(".mode-toggle"); if (modeToggle !== null) { modeToggle.addEventListener('click', reloadDisqus); window.matchMedia('(prefers-color-scheme: dark)').addEventListener('change', reloadDisqus); } </script></div></div></div><footer class="d-flex w-100 justify-content-center"><div class="d-flex justify-content-between align-items-center"><div class="footer-left"><p class="mb-0"> © 2025 <a href=""></a>. <span data-toggle="tooltip" data-placement="top" title="Except where otherwise noted, the blog posts on this site are licensed under the Creative Commons Attribution 4.0 International (CC BY 4.0) License by the author.">Some rights reserved.</span></p></div><div class="footer-right"><p class="mb-0"> Powered by <a href="https://jekyllrb.com" target="_blank" rel="noopener">Jekyll</a> with <a href="https://github.com/cotes2020/jekyll-theme-chirpy" target="_blank" rel="noopener">Chirpy</a> theme.</p></div><div id="post-disqus" class="container"><div id="disqus_thread" class="pt-2 pb-2"><p class="text-center text-muted small"> Comments powered by <a href="https://disqus.com/">Disqus</a>.</p></div><script type="text/javascript"> var disqus_config = function () { this.page.url = 'https://jiyeonnn03.github.io/posts/paper_ai_1/'; this.page.identifier = '/posts/paper_ai_1/'; }; /* Lazy loading */ var disqus_observer = new IntersectionObserver(function (entries) { if(entries[0].isIntersecting) { (function () { var d = document, s = d.createElement('script'); // s.src = 'https://jiyeonnn03-github-io.disqus.com/embed.js'; s.src = 'https://jiyeonnn03-github-io.disqus.com/embed.js'; s.setAttribute('data-timestamp', +new Date()); (d.head || d.body).appendChild(s); })(); disqus_observer.disconnect(); } }, { threshold: [0] }); disqus_observer.observe(document.querySelector('#disqus_thread')); /* Auto switch theme */ function reloadDisqus() { /* Disqus hasn't been loaded */ if (typeof DISQUS === "undefined") { return; } if (document.readyState == 'complete') { DISQUS.reset({ reload: true, config: disqus_config }); } } const modeToggle = document.querySelector(".mode-toggle"); if (modeToggle !== null) { modeToggle.addEventListener('click', reloadDisqus); window.matchMedia('(prefers-color-scheme: dark)').addEventListener('change', reloadDisqus); } </script></div></div></footer></div><div id="search-result-wrapper" class="d-flex justify-content-center unloaded"><div class="col-12 col-sm-11 post-content"><div id="search-hints"><h4 class="text-muted mb-4">Trending Tags</h4><a class="post-tag" href="/tags/til/">TIL</a> <a class="post-tag" href="/tags/tir/">TIR</a> <a class="post-tag" href="/tags/99%ED%81%B4%EB%9F%BD/">99클럽</a> <a class="post-tag" href="/tags/%EA%B0%9C%EB%B0%9C%EC%9E%90%EC%B7%A8%EC%97%85/">개발자취업</a> <a class="post-tag" href="/tags/%EC%BD%94%EB%94%A9%ED%85%8C%EC%8A%A4%ED%8A%B8%EC%A4%80%EB%B9%84/">코딩테스트준비</a> <a class="post-tag" href="/tags/%ED%95%AD%ED%95%B499/">항해99</a> <a class="post-tag" href="/tags/ai/">AI</a> <a class="post-tag" href="/tags/lgaimers/">LGAimers</a> <a class="post-tag" href="/tags/paper-review/">paper review</a> <a class="post-tag" href="/tags/ai/">ai</a></div><div id="search-results" class="d-flex flex-wrap justify-content-center text-muted mt-3"></div></div></div></div><div id="mask"></div><a id="back-to-top" href="#" aria-label="back-to-top" class="btn btn-lg btn-box-shadow" role="button"> <i class="fas fa-angle-up"></i> </a> <script src="https://cdn.jsdelivr.net/npm/simple-jekyll-search@1.10.0/dest/simple-jekyll-search.min.js"></script> <script> SimpleJekyllSearch({ searchInput: document.getElementById('search-input'), resultsContainer: document.getElementById('search-results'), json: '/assets/js/data/search.json', searchResultTemplate: '<div class="pl-1 pr-1 pl-sm-2 pr-sm-2 pl-lg-4 pr-lg-4 pl-xl-0 pr-xl-0"> <a href="https://jiyeonnn03.github.io{url}">{title}</a><div class="post-meta d-flex flex-column flex-sm-row text-muted mt-1 mb-1"> {categories} {tags}</div><p>{snippet}</p></div>', noResultsText: '<p class="mt-5">Oops! No result founds.</p>', templateMiddleware: function(prop, value, template) { if (prop === 'categories') { if (value === '') { return `${value}`; } else { return `<div class="mr-sm-4"><i class="far fa-folder fa-fw"></i>${value}</div>`; } } if (prop === 'tags') { if (value === '') { return `${value}`; } else { return `<div><i class="fa fa-tag fa-fw"></i>${value}</div>`; } } } }); </script> <script src="https://cdn.jsdelivr.net/combine/npm/lozad/dist/lozad.min.js,npm/magnific-popup@1/dist/jquery.magnific-popup.min.js,npm/clipboard@2/dist/clipboard.min.js"></script> <script defer src="/assets/js/dist/post.min.js"></script> <script src="https://cdn.jsdelivr.net/combine/npm/popper.js@1.16.1,npm/bootstrap@4/dist/js/bootstrap.min.js"></script> <script defer src="/app.js"></script> <script defer src="https://www.googletagmanager.com/gtag/js?id="></script> <script> document.addEventListener("DOMContentLoaded", function(event) { window.dataLayer = window.dataLayer || []; function gtag(){dataLayer.push(arguments);} gtag('js', new Date()); gtag('config', ''); }); </script>
